{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4bca3b7-1dbd-4fca-9c82-69a047f82932",
   "metadata": {},
   "source": [
    "## Extracting CTA Bus stops file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f98f8e1-0c7d-44c4-a1f2-8070ab0ec4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import zipfile\n",
    "import os\n",
    "import geopandas as gpd\n",
    "from pykml import parser\n",
    "from lxml import etree\n",
    "import xml.etree.ElementTree as ET\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "import requests\n",
    "import pandas as pd\n",
    "from shapely.ops import unary_union\n",
    "import random\n",
    "from shapely.geometry import Point, box\n",
    "from folium.plugins import FastMarkerCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "942b8baa-5c92-4d66-b033-965c0d24261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the KMZ file to get KML file\n",
    "kmz_file = 'C:/Users/kaur6/Downloads/Urban Analytics/CTA_BusStops.kmz'\n",
    "\n",
    "with zipfile.ZipFile(kmz_file, 'r') as kmz:\n",
    "    kmz.extractall('extracted_kmz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cce864-755a-48bf-bfda-8bcbcd03710f",
   "metadata": {},
   "source": [
    "## Visualizing CTA bus stops on Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64738655-5e22-4b1f-ab43-c4bc21ea2de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Map saved as 'C:/Users/kaur6/Downloads/Urban Analytics/bus_stops_map.html'. Open this file in a browser to view.\n"
     ]
    }
   ],
   "source": [
    "# Load the KML file\n",
    "kml_file = \"C:/Users/kaur6/Downloads/Urban Analytics/extracted_kmz_b/CTA_BusStops.kml\"\n",
    "tree = ET.parse(kml_file)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Define KML namespace\n",
    "namespace = {'kml': 'http://www.opengis.net/kml/2.2'}\n",
    "\n",
    "# Extract all Placemark elements\n",
    "placemarks = root.findall('.//kml:Placemark', namespaces=namespace)\n",
    "\n",
    "# Extract coordinates (longitude, latitude)\n",
    "bus_stops = []\n",
    "for placemark in placemarks:\n",
    "    coordinates = placemark.find('.//kml:coordinates', namespaces=namespace)\n",
    "    if coordinates is not None:\n",
    "        # KML format: longitude,latitude\n",
    "        coords = coordinates.text.strip().split(',')\n",
    "        longitude = float(coords[0])\n",
    "        latitude = float(coords[1])\n",
    "        bus_stops.append((latitude, longitude))\n",
    "\n",
    "# Create a map centered at the first bus stop\n",
    "if bus_stops:\n",
    "    first_stop = bus_stops[0]\n",
    "    m = folium.Map(location=first_stop, zoom_start=12)\n",
    "\n",
    "    # Use MarkerCluster for efficiency\n",
    "    marker_cluster = MarkerCluster().add_to(m)\n",
    "\n",
    "    # Add all bus stops to the cluster\n",
    "    for lat, lon in bus_stops:\n",
    "        folium.Marker(\n",
    "            [lat, lon], \n",
    "            popup=f\"Bus Stop: {lat}, {lon}\"\n",
    "        ).add_to(marker_cluster)\n",
    "\n",
    "    # Save and display the map\n",
    "    output_file = \"C:/Users/kaur6/Downloads/Urban Analytics/bus_stops_map.html\"\n",
    "    m.save(output_file)\n",
    "    print(f\"✅ Map saved as '{output_file}'. Open this file in a browser to view.\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ No bus stops found in the KML file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcffc13-a130-4993-8118-a2fa6cf14bf6",
   "metadata": {},
   "source": [
    "## Extracting CTA Train Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "354fa832-5458-4501-b02a-6c97770216b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the KMZ file to get KML file\n",
    "kmz_r_file = 'C:/Users/kaur6/Downloads/Urban Analytics/CTA_RailStations.kmz'  # Path to your KMZ file\n",
    "with zipfile.ZipFile(kmz_r_file, 'r') as kmz:\n",
    "    kmz.extractall('extracted_kmz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58b01e0-ee6c-44bd-b94d-b725d2cd5f3a",
   "metadata": {},
   "source": [
    "## Visualizing CTA train stations on Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9cfad9-da5b-47a2-805a-51aabf2c3c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the KML file\n",
    "kml_r_file = \"C:/Users/kaur6/Downloads/Urban Analytics/extracted_kmz_r/CTA_RailStations.kml\"\n",
    "tree = ET.parse(kml_r_file)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Define KML namespace\n",
    "namespace = {'kml': 'http://www.opengis.net/kml/2.2'}\n",
    "\n",
    "# Extract all Placemark elements\n",
    "placemarks = root.findall('.//kml:Placemark', namespaces=namespace)\n",
    "\n",
    "# Extract coordinates (longitude, latitude)\n",
    "rail_stations = []\n",
    "for placemark in placemarks:\n",
    "    coordinates = placemark.find('.//kml:coordinates', namespaces=namespace)\n",
    "    if coordinates is not None:\n",
    "        # KML format: longitude,latitude\n",
    "        coords = coordinates.text.strip().split(',')\n",
    "        longitude = float(coords[0])\n",
    "        latitude = float(coords[1])\n",
    "        rail_stations.append((latitude, longitude))\n",
    "\n",
    "# Create a map centered at the first rail station\n",
    "if rail_stations:\n",
    "    first_station = rail_stations[0]\n",
    "    m = folium.Map(location=first_station, zoom_start=12)\n",
    "\n",
    "    # Add markers for all bus stops\n",
    "    for lat, lon in rail_stations:\n",
    "        folium.Marker([lat, lon], popup=f\"Rail Station: {lat}, {lon}\").add_to(m)\n",
    "\n",
    "    # Save and display the map\n",
    "    m.save(\"rail_stations_map.html\")\n",
    "    print(\"Map saved as 'rail_stations_map.html'. Open this file in a browser to view.\")\n",
    "\n",
    "else:\n",
    "    print(\"No rail stations found in the KML file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13ecbe2-b681-4568-befd-b0713a7f2922",
   "metadata": {},
   "source": [
    "## Getting Metra Stations in Cook County from Overpass API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a5baf0b-beb7-4af5-a51b-9c3162e5d1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Metra stations to metra_stations_cook_county.geojson and metra_stations_cook_county.csv\n"
     ]
    }
   ],
   "source": [
    "# Overpass Turbo API URL\n",
    "overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "query = \"\"\"\n",
    "[out:json];\n",
    "area[name=\"Cook County\"]->.searchArea;\n",
    "node[\"railway\"=\"station\"][\"operator\"~\"Metra\"](area.searchArea);\n",
    "out body;\n",
    "\"\"\"\n",
    "\n",
    "# Fetch data from Overpass API\n",
    "response = requests.get(overpass_url, params={\"data\": query})\n",
    "data = response.json()\n",
    "\n",
    "# Extract relevant information (ID, name, latitude, longitude)\n",
    "stations = []\n",
    "for element in data[\"elements\"]:\n",
    "    if \"lat\" in element and \"lon\" in element:\n",
    "        name = element[\"tags\"].get(\"name\", \"Unknown Station\")\n",
    "        stations.append({\n",
    "            \"ID\": element[\"id\"],\n",
    "            \"Name\": name,\n",
    "            \"Latitude\": element[\"lat\"],\n",
    "            \"Longitude\": element[\"lon\"]\n",
    "        })\n",
    "\n",
    "# Convert to GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(stations, geometry=gpd.points_from_xy(\n",
    "    [s[\"Longitude\"] for s in stations], [s[\"Latitude\"] for s in stations]\n",
    "))\n",
    "\n",
    "# Set CRS for Metra stations (WGS 84 - EPSG:4326)\n",
    "gdf.set_crs(\"EPSG:4326\", allow_override=True, inplace=True)\n",
    "\n",
    "# Save as GeoJSON and CSV\n",
    "geojson_path = \"metra_stations_cook_county.geojson\"\n",
    "csv_path = \"metra_stations_cook_county.csv\"\n",
    "gdf.to_file(geojson_path, driver=\"GeoJSON\")\n",
    "gdf.drop(columns=[\"geometry\"]).to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Saved Metra stations to {geojson_path} and {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383d08f3-b02e-4165-8702-f6a7cd135655",
   "metadata": {},
   "source": [
    "## Visualizing CTA and Metra Stations on same map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b09a63e6-97a9-44da-bb33-4b138a9c469d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CTA Rail Stations: 144\n",
      "Number of Metra Rail Stations: 132\n",
      "Map saved as 'cta_metra_stations_map.html'. Open this file in a browser to view.\n"
     ]
    }
   ],
   "source": [
    "# Define KML namespace\n",
    "namespace = {'kml': 'http://www.opengis.net/kml/2.2'}\n",
    "\n",
    "# Load CTA Rail Stations KML file\n",
    "kml_r_file = \"C:/Users/kaur6/Downloads/Urban Analytics/extracted_kmz_r/CTA_RailStations.kml\"\n",
    "tree = ET.parse(kml_r_file)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Extract all Placemark elements\n",
    "placemarks = root.findall('.//kml:Placemark', namespaces=namespace)\n",
    "\n",
    "# Extract CTA rail station coordinates\n",
    "cta_stations = []\n",
    "for placemark in placemarks:\n",
    "    coordinates = placemark.find('.//kml:coordinates', namespaces=namespace)\n",
    "    if coordinates is not None:\n",
    "        coords = coordinates.text.strip().split(',')\n",
    "        longitude = float(coords[0])\n",
    "        latitude = float(coords[1])\n",
    "        cta_stations.append((latitude, longitude))\n",
    "\n",
    "# Print number of CTA stations\n",
    "print(f\"Number of CTA Rail Stations: {len(cta_stations)}\")\n",
    "\n",
    "# Convert CTA data to a GeoDataFrame\n",
    "cta_gdf = gpd.GeoDataFrame(cta_stations, columns=[\"Latitude\", \"Longitude\"], \n",
    "                           geometry=[Point(lon, lat) for lat, lon in cta_stations])\n",
    "\n",
    "# Load Metra Rail Stations from GeoJSON\n",
    "metra_gdf = gpd.read_file(\"C:/Users/kaur6/Downloads/Urban Analytics/metra_stations_cook_county.geojson\")\n",
    "\n",
    "# Print number of Metra stations\n",
    "print(f\"Number of Metra Rail Stations: {len(metra_gdf)}\")\n",
    "\n",
    "# Create a Folium map centered at an average location\n",
    "map_center = [cta_gdf[\"Latitude\"].mean(), cta_gdf[\"Longitude\"].mean()]\n",
    "m = folium.Map(location=map_center, zoom_start=11)\n",
    "\n",
    "# Add CTA stations (Blue markers)\n",
    "for idx, row in cta_gdf.iterrows():\n",
    "    folium.Marker(\n",
    "        location=[row[\"Latitude\"], row[\"Longitude\"]],\n",
    "        popup=f\"CTA Rail Station: {row['Latitude']}, {row['Longitude']}\",\n",
    "        icon=folium.Icon(color=\"blue\", icon=\"train\")\n",
    "    ).add_to(m)\n",
    "\n",
    "# Add Metra stations (Red markers)\n",
    "for idx, row in metra_gdf.iterrows():\n",
    "    folium.Marker(\n",
    "        location=[row[\"Latitude\"], row[\"Longitude\"]],\n",
    "        popup=f\"Metra Station: {row['Name']}\",\n",
    "        icon=folium.Icon(color=\"red\", icon=\"train\")\n",
    "    ).add_to(m)\n",
    "\n",
    "# Save and display the map\n",
    "m.save(\"cta_metra_stations_map.html\")\n",
    "print(\"Map saved as 'cta_metra_stations_map.html'. Open this file in a browser to view.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4494090e-30e7-4d8f-bb53-ad587df5746c",
   "metadata": {},
   "source": [
    "## Getting valid unique pins from the pins of cook county dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20049497-83fb-4d8b-b389-172fd169f6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Chunk 1...\n",
      "Chunk 1: 100000 rows → 77896 valid rows after NaN removal.\n",
      "Chunk 1: Added 77896 pins. Total pins so far: 77896\n",
      "Chunk 1 processing complete.\n",
      "\n",
      "\n",
      "Processing Chunk 2...\n",
      "Chunk 2: 100000 rows → 78087 valid rows after NaN removal.\n",
      "Chunk 2: Added 78087 pins. Total pins so far: 155983\n",
      "Chunk 2 processing complete.\n",
      "\n",
      "\n",
      "Processing Chunk 3...\n",
      "Chunk 3: 100000 rows → 78009 valid rows after NaN removal.\n",
      "Chunk 3: Added 78009 pins. Total pins so far: 233992\n",
      "Chunk 3 processing complete.\n",
      "\n",
      "\n",
      "Processing Chunk 4...\n",
      "Chunk 4: 100000 rows → 77958 valid rows after NaN removal.\n",
      "Chunk 4: Added 77958 pins. Total pins so far: 311950\n",
      "Chunk 4 processing complete.\n",
      "\n",
      "\n",
      "Processing Chunk 5...\n",
      "Chunk 5: 100000 rows → 78032 valid rows after NaN removal.\n",
      "Chunk 5: Added 78032 pins. Total pins so far: 389982\n",
      "Chunk 5 processing complete.\n",
      "\n",
      "\n",
      "Processing Chunk 6...\n",
      "Chunk 6: 100000 rows → 78007 valid rows after NaN removal.\n",
      "Chunk 6: Added 78007 pins. Total pins so far: 467989\n",
      "Chunk 6 processing complete.\n",
      "\n",
      "\n",
      "Processing Chunk 7...\n",
      "Chunk 7: 100000 rows → 77699 valid rows after NaN removal.\n",
      "Chunk 7: Added 77699 pins. Total pins so far: 545688\n",
      "Chunk 7 processing complete.\n",
      "\n",
      "\n",
      "Processing Chunk 8...\n",
      "Chunk 8: 100000 rows → 77828 valid rows after NaN removal.\n",
      "Chunk 8: Added 77828 pins. Total pins so far: 623516\n",
      "Chunk 8 processing complete.\n",
      "\n",
      "\n",
      "Processing Chunk 9...\n",
      "Chunk 9: 100000 rows → 77887 valid rows after NaN removal.\n",
      "Chunk 9: Added 77887 pins. Total pins so far: 701403\n",
      "Chunk 9 processing complete.\n",
      "\n",
      "\n",
      "Processing Chunk 10...\n",
      "Chunk 10: 100000 rows → 77774 valid rows after NaN removal.\n",
      "Chunk 10: Added 77774 pins. Total pins so far: 779177\n",
      "Chunk 10 processing complete.\n",
      "\n",
      "\n",
      "Processing Chunk 11...\n",
      "Chunk 11: 100000 rows → 77687 valid rows after NaN removal.\n",
      "Chunk 11: Added 77687 pins. Total pins so far: 856864\n",
      "Chunk 11 processing complete.\n",
      "\n",
      "\n",
      "Processing Chunk 12...\n",
      "Chunk 12: 39209 rows → 30503 valid rows after NaN removal.\n",
      "Chunk 12: Added 30503 pins. Total pins so far: 887367\n",
      "Chunk 12 processing complete.\n",
      "\n",
      "\n",
      "Map saved as 'C:/Users/kaur6/Downloads/Urban Analytics/pins_on_map.html'. Open this file in a browser to view.\n",
      "Total number of valid PINs: 887367\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "input_file = \"C:/Users/kaur6/Downloads/Urban Analytics/pin_lat_long.csv\"\n",
    "output_file = \"C:/Users/kaur6/Downloads/Urban Analytics/pins_on_map.html\"\n",
    "\n",
    "# Define chunk size\n",
    "chunk_size = 100000 \n",
    "\n",
    "# Initialize the map\n",
    "map_center = [0, 0]  # Placeholder until we get valid coordinates\n",
    "m = folium.Map(location=map_center, zoom_start=12)\n",
    "\n",
    "# Initialize total pin counter\n",
    "total_pins = 0\n",
    "chunk_count = 0 \n",
    "\n",
    "# Process data in chunks\n",
    "for chunk in pd.read_csv(input_file, chunksize=chunk_size):\n",
    "    chunk_count += 1\n",
    "    print(f\"\\nProcessing Chunk {chunk_count}...\")\n",
    "\n",
    "    # Check for NaN values and remove them\n",
    "    before_drop = len(chunk)\n",
    "    chunk = chunk.dropna(subset=['latitude', 'longitude'])\n",
    "    after_drop = len(chunk)\n",
    "    \n",
    "    print(f\"Chunk {chunk_count}: {before_drop} rows → {after_drop} valid rows after NaN removal.\")\n",
    "\n",
    "    # If all rows are NaN, skip this chunk\n",
    "    if chunk.empty:\n",
    "        print(f\"Chunk {chunk_count} is empty after NaN removal. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Convert chunk into a GeoDataFrame\n",
    "    try:\n",
    "        gdf = gpd.GeoDataFrame(chunk, \n",
    "                               geometry=gpd.points_from_xy(chunk['longitude'], chunk['latitude']),\n",
    "                               crs=\"EPSG:4326\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in Chunk {chunk_count}: {e}\")\n",
    "        continue  \n",
    "\n",
    "    # Update total pin count\n",
    "    total_pins += len(gdf)\n",
    "    print(f\"Chunk {chunk_count}: Added {len(gdf)} pins. Total pins so far: {total_pins}\")\n",
    "\n",
    "    # Update map center with first valid chunk\n",
    "    if total_pins == len(gdf):\n",
    "        map_center = [gdf[\"latitude\"].mean(), gdf[\"longitude\"].mean()]\n",
    "        m.location = map_center\n",
    "        m.zoom_start = 12\n",
    "\n",
    "    # Add markers for each valid row (Limit to first 5000 to avoid slowing down)\n",
    "    for idx, row in gdf.iterrows():\n",
    "        folium.Marker(\n",
    "            location=[row[\"latitude\"], row[\"longitude\"]],\n",
    "            popup=f\"PIN: {row.get('pin', 'No pin')}\",\n",
    "            icon=folium.Icon(color=\"blue\", icon=\"info-sign\")\n",
    "        ).add_to(m)\n",
    "        \n",
    "        if idx >= 5000:  # Prevent too many markers slowing down the map\n",
    "            break\n",
    "\n",
    "    print(f\"Chunk {chunk_count} processing complete.\\n\")\n",
    "\n",
    "# Save the map after processing all chunks\n",
    "m.save(output_file)\n",
    "print(f\"\\nMap saved as '{output_file}'. Open this file in a browser to view.\")\n",
    "print(f\"Total number of valid PINs: {total_pins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4cfa6c-0649-4b5d-bf4d-9890c5b402d6",
   "metadata": {},
   "source": [
    "## Getting pins which are in distance of 0.5 miles from a train station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdff2324-ff5c-4bc2-ae55-2a36abc75cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 142402 PINs within 0.5 miles of a train station.\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "pin_file = \"C:/Users/kaur6/Downloads/Urban Analytics/pin_lat_long.csv\"\n",
    "metra_file = \"C:/Users/kaur6/Downloads/Urban Analytics/metra_stations_cook_county.geojson\"\n",
    "cta_kml_file = \"C:/Users/kaur6/Downloads/Urban Analytics/extracted_kmz_r/CTA_RailStations.kml\"\n",
    "\n",
    "# Load PIN data\n",
    "pins_df = pd.read_csv(pin_file)\n",
    "\n",
    "# Drop rows with missing coordinates\n",
    "pins_df = pins_df.dropna(subset=['latitude', 'longitude'])\n",
    "\n",
    "# Convert PINs to a GeoDataFrame\n",
    "pins_gdf = gpd.GeoDataFrame(\n",
    "    pins_df, \n",
    "    geometry=gpd.points_from_xy(pins_df['longitude'], pins_df['latitude']),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Convert to metric projection for distance calculation (Meters)\n",
    "pins_gdf = pins_gdf.to_crs(\"EPSG:3857\")\n",
    "\n",
    "# Load Metra stations\n",
    "metra_gdf = gpd.read_file(metra_file)\n",
    "\n",
    "# Convert Metra stations to metric CRS\n",
    "metra_gdf = metra_gdf.to_crs(\"EPSG:3857\")\n",
    "\n",
    "# Load CTA Rail Stations from KML\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Define KML namespace\n",
    "namespace = {'kml': 'http://www.opengis.net/kml/2.2'}\n",
    "\n",
    "# Parse KML file\n",
    "tree = ET.parse(cta_kml_file)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Extract CTA stations\n",
    "cta_stations = []\n",
    "for placemark in root.findall('.//kml:Placemark', namespaces=namespace):\n",
    "    coordinates = placemark.find('.//kml:coordinates', namespaces=namespace)\n",
    "    if coordinates is not None:\n",
    "        lon, lat, _ = map(float, coordinates.text.strip().split(','))\n",
    "        cta_stations.append(Point(lon, lat))\n",
    "\n",
    "# Convert CTA stations to a GeoDataFrame\n",
    "cta_gdf = gpd.GeoDataFrame(geometry=cta_stations, crs=\"EPSG:4326\")\n",
    "cta_gdf = cta_gdf.to_crs(\"EPSG:3857\")  # Convert to meters\n",
    "\n",
    "# Combine CTA and Metra station geometries using pd.concat()\n",
    "all_stations_gdf = pd.concat([cta_gdf, metra_gdf], ignore_index=True)\n",
    "\n",
    "# Create buffer zone of 0.5 miles (≈ 804 meters)\n",
    "station_buffer = all_stations_gdf.buffer(804)\n",
    "\n",
    "# Find PINs within the buffer zone\n",
    "pins_near_stations = pins_gdf[pins_gdf.geometry.within(unary_union(station_buffer))]\n",
    "\n",
    "# Convert back to Latitude/Longitude for mapping\n",
    "pins_near_stations = pins_near_stations.to_crs(\"EPSG:4326\")\n",
    "\n",
    "# Save results\n",
    "pins_near_stations.to_csv(\"C:/Users/kaur6/Downloads/Urban Analytics/pins_near_train_stations.csv\", index=False)\n",
    "\n",
    "print(f\"✅ Found {len(pins_near_stations)} PINs within 0.5 miles of a train station.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b08fc1f-c634-4470-8433-994edb957b3f",
   "metadata": {},
   "source": [
    "## Visualizing 5000 pins on the map due to memory constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8533bb47-b229-4022-aa7f-0031a09a93f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Map saved as 'C:/Users/kaur6/Downloads/Urban Analytics/pins_near_train_stations_map.html'. Open this file in a browser to view.\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "pins_near_stations_file = \"C:/Users/kaur6/Downloads/Urban Analytics/pins_near_train_stations.csv\"\n",
    "metra_file = \"C:/Users/kaur6/Downloads/Urban Analytics/metra_stations_cook_county.geojson\"\n",
    "cta_kml_file = \"C:/Users/kaur6/Downloads/Urban Analytics/extracted_kmz_r/CTA_RailStations.kml\"\n",
    "\n",
    "# Load the results of PINs near stations\n",
    "pins_near_stations = pd.read_csv(pins_near_stations_file)\n",
    "\n",
    "# Convert to a GeoDataFrame\n",
    "pins_near_stations_gdf = gpd.GeoDataFrame(\n",
    "    pins_near_stations,\n",
    "    geometry=gpd.points_from_xy(pins_near_stations['longitude'], pins_near_stations['latitude']),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Load Metra stations\n",
    "metra_gdf = gpd.read_file(metra_file)\n",
    "\n",
    "# Load CTA Rail Stations from KML\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Define KML namespace\n",
    "namespace = {'kml': 'http://www.opengis.net/kml/2.2'}\n",
    "\n",
    "# Parse KML file\n",
    "tree = ET.parse(cta_kml_file)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Extract CTA stations\n",
    "cta_stations = []\n",
    "for placemark in root.findall('.//kml:Placemark', namespaces=namespace):\n",
    "    coordinates = placemark.find('.//kml:coordinates', namespaces=namespace)\n",
    "    if coordinates is not None:\n",
    "        lon, lat, _ = map(float, coordinates.text.strip().split(','))\n",
    "        cta_stations.append((lat, lon))\n",
    "\n",
    "# Initialize the map centered around an average location\n",
    "map_center = [pins_near_stations_gdf[\"latitude\"].mean(), pins_near_stations_gdf[\"longitude\"].mean()]\n",
    "m = folium.Map(location=map_center, zoom_start=12)\n",
    "\n",
    "# Add Metra station markers\n",
    "for _, row in metra_gdf.iterrows():\n",
    "    folium.Marker(\n",
    "        location=[row.geometry.y, row.geometry.x],\n",
    "        popup=f\"Metra Station: {row.geometry.y}, {row.geometry.x}\",\n",
    "        icon=folium.Icon(color=\"red\", icon=\"info-sign\")\n",
    "    ).add_to(m)\n",
    "\n",
    "# Add CTA station markers\n",
    "for lat, lon in cta_stations:\n",
    "    folium.Marker(\n",
    "        location=[lat, lon],\n",
    "        popup=f\"CTA Station: {lat}, {lon}\",\n",
    "        icon=folium.Icon(color=\"green\", icon=\"info-sign\")\n",
    "    ).add_to(m)\n",
    "\n",
    "# Sample 1000 pins randomly\n",
    "sampled_pins = pins_near_stations_gdf.sample(n=5000, random_state=42)\n",
    "\n",
    "# Use MarkerCluster to group pins efficiently\n",
    "marker_cluster = MarkerCluster().add_to(m)\n",
    "\n",
    "# Add sampled PIN markers\n",
    "for _, row in sampled_pins.iterrows():\n",
    "    folium.Marker(\n",
    "        location=[row[\"latitude\"], row[\"longitude\"]],\n",
    "        popup=f\"PIN: {row.get('pin', 'No pin')} is within 0.5 miles of a station\",\n",
    "        icon=folium.Icon(color=\"blue\", icon=\"info-sign\")\n",
    "    ).add_to(marker_cluster)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "output_map_file = \"C:/Users/kaur6/Downloads/Urban Analytics/pins_near_train_stations_map.html\"\n",
    "m.save(output_map_file)\n",
    "\n",
    "print(f\"✅ Map saved as '{output_map_file}'. Open this file in a browser to view.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9bed3d-fcf7-433c-aeaf-5bdf281922c5",
   "metadata": {},
   "source": [
    "## Getting pins which lie in distance of 0.25 miles from CTA bus stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9f0cf05-83c0-417c-a857-4b24b6e109b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 389675 PINs within 0.25 miles of a CTA bus stop.\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "pin_file = \"C:/Users/kaur6/Downloads/Urban Analytics/pin_lat_long.csv\"\n",
    "cta_bus_stop_kml_file = \"C:/Users/kaur6/Downloads/Urban Analytics/extracted_kmz_b/CTA_BusStops.kml\"\n",
    "\n",
    "# Load PIN data\n",
    "pins_df = pd.read_csv(pin_file)\n",
    "\n",
    "# Drop rows with missing coordinates\n",
    "pins_df = pins_df.dropna(subset=['latitude', 'longitude'])\n",
    "\n",
    "# Convert PINs to a GeoDataFrame\n",
    "pins_gdf = gpd.GeoDataFrame(\n",
    "    pins_df, \n",
    "    geometry=gpd.points_from_xy(pins_df['longitude'], pins_df['latitude']),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Convert to metric projection for distance calculation (Meters)\n",
    "pins_gdf = pins_gdf.to_crs(\"EPSG:3857\")\n",
    "\n",
    "# Load CTA Bus Stops from KML\n",
    "namespace = {'kml': 'http://www.opengis.net/kml/2.2'}\n",
    "\n",
    "# Parse KML file\n",
    "tree = ET.parse(cta_bus_stop_kml_file)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Extract CTA bus stops\n",
    "cta_bus_stops = []\n",
    "for placemark in root.findall('.//kml:Placemark', namespaces=namespace):\n",
    "    coordinates = placemark.find('.//kml:coordinates', namespaces=namespace)\n",
    "    if coordinates is not None:\n",
    "        lon, lat, _ = map(float, coordinates.text.strip().split(','))\n",
    "        cta_bus_stops.append(Point(lon, lat))\n",
    "\n",
    "# Convert CTA bus stops to a GeoDataFrame\n",
    "cta_bus_stops_gdf = gpd.GeoDataFrame(geometry=cta_bus_stops, crs=\"EPSG:4326\")\n",
    "cta_bus_stops_gdf = cta_bus_stops_gdf.to_crs(\"EPSG:3857\")  # Convert to meters\n",
    "\n",
    "# Create buffer zone of 0.25 miles (≈ 402 meters)\n",
    "bus_stop_buffer = cta_bus_stops_gdf.buffer(402)\n",
    "\n",
    "# Find PINs within the buffer zone\n",
    "pins_near_bus_stops = pins_gdf[pins_gdf.geometry.within(unary_union(bus_stop_buffer))]\n",
    "\n",
    "# Convert back to Latitude/Longitude for mapping\n",
    "pins_near_bus_stops = pins_near_bus_stops.to_crs(\"EPSG:4326\")\n",
    "\n",
    "# Save results\n",
    "pins_near_bus_stops.to_csv(\"C:/Users/kaur6/Downloads/Urban Analytics/pins_near_bus_stops.csv\", index=False)\n",
    "\n",
    "print(f\"✅ Found {len(pins_near_bus_stops)} PINs within 0.25 miles of a CTA bus stop.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5a5662-f800-42f9-a0e7-b66f5dcac042",
   "metadata": {},
   "source": [
    "## Visualizing 5000 pins on the map due to memory constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37e5dd23-d9bb-45f9-9d93-e5ccd51cebe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map with sampled PINs and all CTA Bus Stops saved as 'pins_near_bus_stops_map.html'. Open this file in a browser to view.\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "pins_file = \"C:/Users/kaur6/Downloads/Urban Analytics/pins_near_bus_stops.csv\"\n",
    "cta_bus_stops_kml = \"C:/Users/kaur6/Downloads/Urban Analytics/extracted_kmz_b/CTA_BusStops.kml\"\n",
    "\n",
    "# Load the data\n",
    "pins_df = pd.read_csv(pins_file)\n",
    "\n",
    "# Randomly sample 5000 PINs\n",
    "sampled_pins = pins_df.sample(n=5000, random_state=42)\n",
    "\n",
    "# Load CTA Bus Stops from KML\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "namespace = {'kml': 'http://www.opengis.net/kml/2.2'}\n",
    "tree = ET.parse(cta_bus_stops_kml)\n",
    "root = tree.getroot()\n",
    "\n",
    "cta_bus_stops = []\n",
    "for placemark in root.findall('.//kml:Placemark', namespaces=namespace):\n",
    "    coordinates = placemark.find('.//kml:coordinates', namespaces=namespace)\n",
    "    if coordinates is not None:\n",
    "        lon, lat, _ = map(float, coordinates.text.strip().split(','))\n",
    "        cta_bus_stops.append((lat, lon))\n",
    "\n",
    "# Create the map centered at the first sampled pin\n",
    "first_sampled_pin = sampled_pins.iloc[0]\n",
    "m = folium.Map(location=[first_sampled_pin['latitude'], first_sampled_pin['longitude']], zoom_start=12)\n",
    "\n",
    "# Create MarkerCluster for PINs\n",
    "pins_marker_cluster = MarkerCluster().add_to(m)\n",
    "\n",
    "# Add sampled PINs to the MarkerCluster with a blue icon\n",
    "for _, row in sampled_pins.iterrows():\n",
    "    folium.Marker(\n",
    "        location=[row['latitude'], row['longitude']],\n",
    "        popup=f\"PIN: {row['pin']}\",\n",
    "        icon=folium.Icon(color='blue')  # Set pin icon to blue\n",
    "    ).add_to(pins_marker_cluster)\n",
    "\n",
    "# Create MarkerCluster for CTA Bus Stops\n",
    "bus_stops_marker_cluster = MarkerCluster().add_to(m)\n",
    "\n",
    "# Add CTA Bus Stops to the map with red icon\n",
    "for lat, lon in cta_bus_stops:\n",
    "    folium.Marker(\n",
    "        location=[lat, lon],\n",
    "        popup=\"CTA Bus Stop\",\n",
    "        icon=folium.Icon(color='red', icon='info-sign')  # Red icon for bus stops\n",
    "    ).add_to(bus_stops_marker_cluster)\n",
    "\n",
    "# Save the map\n",
    "m.save(\"C:/Users/kaur6/Downloads/Urban Analytics/pins_near_bus_stops_map.html\")\n",
    "\n",
    "print(\"Map with sampled PINs and all CTA Bus Stops saved as 'pins_near_bus_stops_map.html'. Open this file in a browser to view.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca08f47e-4bd3-4316-a0ff-6ed98da1b6aa",
   "metadata": {},
   "source": [
    "## Merging the pins close to stations and close to bus stops to a common csv making sure the pins are unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90f002b1-0743-4356-ac42-138f4b13e138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique pins in the merged file: 438395\n",
      "Unique pins merged and saved to: C:/Users/kaur6/Downloads/Urban Analytics/pins_near_bus_stop_or_train_station.csv\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "bus_pins_file = \"C:/Users/kaur6/Downloads/Urban Analytics/pins_near_bus_stops.csv\"\n",
    "train_pins_file = \"C:/Users/kaur6/Downloads/Urban Analytics/pins_near_train_stations.csv\"\n",
    "output_file = \"C:/Users/kaur6/Downloads/Urban Analytics/pins_near_bus_stop_or_train_station.csv\"\n",
    "\n",
    "# Load the data\n",
    "bus_pins_df = pd.read_csv(bus_pins_file)\n",
    "train_pins_df = pd.read_csv(train_pins_file)\n",
    "\n",
    "# Concatenate both DataFrames\n",
    "combined_pins_df = pd.concat([bus_pins_df, train_pins_df], ignore_index=True)\n",
    "\n",
    "# Ensure unique pins based on the 'pin' column\n",
    "combined_pins_df = combined_pins_df.drop_duplicates(subset=['pin'], keep='first')\n",
    "\n",
    "# Save the resulting DataFrame to a new CSV file\n",
    "combined_pins_df.to_csv(output_file, index=False)\n",
    "\n",
    "# Print the number of unique pins\n",
    "print(f\"Number of unique pins in the merged file: {len(combined_pins_df)}\")\n",
    "print(f\"Unique pins merged and saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58d6d61-f44b-4ec2-a474-a7c0659f6935",
   "metadata": {},
   "source": [
    "## Getting the zoning class for the parcels in the pins_near_bus_stop_or_train_station.csv data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52849dff-ceb2-4d26-9451-24d502c865de",
   "metadata": {},
   "source": [
    "## Firstly using the Chicago Zoning district data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7facab7-6f8c-4e58-b41e-d32ec06a984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "parcel_data = pd.read_csv('C:/Users/kaur6/Downloads/Urban Analytics/pins_near_bus_stop_or_train_station.csv')\n",
    "zoning_data = pd.read_csv('C:/Users/kaur6/Downloads/Urban Analytics/Zoning_districts.csv')  \n",
    "\n",
    "# Convert to GeoDataFrame\n",
    "parcel_gdf = gpd.GeoDataFrame(parcel_data, geometry=gpd.points_from_xy(parcel_data['longitude'], parcel_data['latitude']))\n",
    "zoning_gdf = gpd.GeoDataFrame(zoning_data, geometry=gpd.GeoSeries.from_wkt(zoning_data['the_geom']))\n",
    "\n",
    "# Set CRS\n",
    "parcel_gdf.set_crs('EPSG:4326', allow_override=True, inplace=True)\n",
    "zoning_gdf.set_crs('EPSG:4326', allow_override=True, inplace=True)\n",
    "\n",
    "# Perform spatial join\n",
    "joined_gdf = gpd.sjoin(parcel_gdf, zoning_gdf, how='left', predicate='within')\n",
    "\n",
    "# Keep only required columns\n",
    "final_gdf = joined_gdf[parcel_data.columns.tolist() + ['ZONE_CLASS']].copy()\n",
    "\n",
    "# Remove duplicates based on unique parcel identifier (e.g., 'pin')\n",
    "#final_gdf = final_gdf.drop_duplicates(subset=['pin'])\n",
    "\n",
    "# Fill missing ZONE_CLASS with 'Unknown'\n",
    "final_gdf.loc[:, 'ZONE_CLASS'] = final_gdf['ZONE_CLASS'].fillna('Unknown')\n",
    "\n",
    "# Drop geometry column to reduce file size\n",
    "final_gdf = final_gdf.drop(columns=['geometry'])\n",
    "\n",
    "# Save final cleaned dataset\n",
    "final_gdf.to_csv('C:/Users/kaur6/Downloads/Urban Analytics/pins_near_bus_stop_or_train_station_with_zone_class.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf951587-7146-481e-bec5-120a798928ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with 'Unknown' ZONE_CLASS: 66471\n",
      "Rows with non-'Unknown' ZONE_CLASS: 371928\n"
     ]
    }
   ],
   "source": [
    "# Count rows with 'Unknown' in 'ZONE_CLASS'\n",
    "unknown_count = joined_gdf[final_gdf['ZONE_CLASS'] == 'Unknown'].shape[0]\n",
    "\n",
    "# Count rows where 'ZONE_CLASS' is not 'Unknown'\n",
    "not_unknown_count = joined_gdf[final_gdf['ZONE_CLASS'] != 'Unknown'].shape[0]\n",
    "\n",
    "# Print the results\n",
    "print(f\"Rows with 'Unknown' ZONE_CLASS: {unknown_count}\")\n",
    "print(f\"Rows with non-'Unknown' ZONE_CLASS: {not_unknown_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6343e90-031e-47b4-bf1c-a13c9ccbc238",
   "metadata": {},
   "source": [
    "## Now, getting Zoning class for the pins whose zone class was Unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd4ef60e-45e8-46f6-89a9-06eb59eb83ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved as C:/Users/kaur6/Downloads/Urban Analytics/pins_near_bs_ts_with_zone_class.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the GeoJSON file\n",
    "geojson_path = \"C:/Users/kaur6/Downloads/Urban Analytics/Zoning_Cook_County.geojson\"  \n",
    "gdf = gpd.read_file(geojson_path)\n",
    "\n",
    "# Ensure the 'geometry' column is set as the active geometry column\n",
    "gdf = gdf.set_geometry('geometry')\n",
    "\n",
    "# Create a spatial index for faster geometry lookup\n",
    "gdf.sindex  # This creates the spatial index for faster lookups\n",
    "\n",
    "# Load the CSV file containing PINs (with Unknown ZONE_CLASS)\n",
    "csv_path = \"C:/Users/kaur6/Downloads/Urban Analytics/pins_near_bus_stop_or_train_station_with_zone_class.csv\" \n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Function to find the ZoneID for a given latitude and longitude using spatial indexing\n",
    "def get_zone_id(lat, lon, gdf):\n",
    "    point = Point(lon, lat)  # Shapely uses (longitude, latitude) format\n",
    "    # Create a bounding box (minx, miny, maxx, maxy) around the point\n",
    "    minx, miny, maxx, maxy = point.bounds\n",
    "    bbox = box(minx, miny, maxx, maxy)  # Create a Shapely geometry for the bounding box\n",
    "    \n",
    "    # Use spatial index query to find geometries that intersect the bounding box\n",
    "    possible_matches_index = list(gdf.sindex.query(bbox, predicate='intersects'))\n",
    "    \n",
    "    # Loop through the possible matches to check if the point is contained\n",
    "    for idx in possible_matches_index:\n",
    "        if gdf.iloc[idx].geometry.contains(point):\n",
    "            return gdf.iloc[idx][\"ZoneID\"]\n",
    "    \n",
    "    return \"Unknown\"  # If no match is found\n",
    "\n",
    "# Iterate over each row of the DataFrame where ZONE_CLASS is \"Unknown\" using apply()\n",
    "def update_zone_class(row):\n",
    "    if row[\"ZONE_CLASS\"] == \"Unknown\":\n",
    "        # Extract the latitude and longitude\n",
    "        latitude = row[\"latitude\"]\n",
    "        longitude = row[\"longitude\"]\n",
    "        \n",
    "        # Get the ZoneID using the get_zone_id function\n",
    "        zone_id = get_zone_id(latitude, longitude, gdf)\n",
    "        \n",
    "        # Update the ZONE_CLASS column with the found ZoneID\n",
    "        return zone_id\n",
    "    return row[\"ZONE_CLASS\"]\n",
    "\n",
    "# Apply the function to update the 'ZONE_CLASS' column\n",
    "df[\"ZONE_CLASS\"] = df.apply(update_zone_class, axis=1)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "output_csv_path = \"C:/Users/kaur6/Downloads/Urban Analytics/pins_near_bs_ts_with_zone_class.csv\"  # Specify the output file path\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Updated CSV saved as {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2440540-82e0-4698-b0d6-2db0a82c1702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with ZONE_CLASS as 'Unknown': 66166\n"
     ]
    }
   ],
   "source": [
    "unknown_count = df[df[\"ZONE_CLASS\"] == \"Unknown\"].shape[0]\n",
    "print(f\"Number of rows with ZONE_CLASS as 'Unknown': {unknown_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fde7422f-9f3a-4ea6-9ffd-2b326564cf7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               pin   latitude  longitude ZONE_CLASS\n",
      "3   17333010410000  41.829544 -87.643993       RT-4\n",
      "5   14201130370000  41.949544 -87.665653     RT-3.5\n",
      "6   17042080140000  41.910595 -87.630613       RM-5\n",
      "12  17193150050000  41.854619 -87.682744       RT-4\n",
      "13  14202100200000  41.951253 -87.656356       RT-4\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file, ensuring PIN is read as a string\n",
    "csv_path = \"C:/Users/kaur6/Downloads/Urban Analytics/pins_near_bs_ts_with_zone_class.csv\"\n",
    "df = pd.read_csv(csv_path)  # Force PIN to be a string\n",
    "\n",
    "# Define the high-density zoning list\n",
    "high_density_zones = [\n",
    "    \"R6\", \"R7\", \"R8\", \"C8\",\n",
    "    \"RT-4\", \"RT-3.5\", \"RM-5\", \"RM-6.5\", \"RM-5.5\", \"RM-6\", \"RM-4.5\",\n",
    "    \"B1-1\", \"B3-1\", \"B3-2\", \"B2-2\", \"B3-3\", \"B1-2\", \"B1-3\", \"B2-3\", \"B2-5\", \"B3-5\",\n",
    "    \"C1-2\", \"C1-1\", \"C1-3\", \"C1-5\", \"C2-2\", \"C2-1\", \"C2-3\", \"C2-5\", \"C3-2\", \"C3-3\", \"C3-5\",\n",
    "    \"DX-3\", \"DX-5\", \"DX-7\", \"DX-12\", \"DX-16\",\n",
    "    \"PD 62\", \"PD 102\", \"PD 112\", \"PD 135\", \"PD 143\", \"PD 157\", \"PD 204\", \"PD 236\", \"PD 250\", \"PD 280\",\n",
    "    \"PD 314\", \"PD 355\", \"PD 362\", \"PD 368\", \"PD 384\", \"PD 395\", \"PD 412\", \"PD 416\", \"PD 420\", \"PD 421\",\n",
    "    \"PD 422\", \"PD 427\", \"PD 441\", \"PD 447\", \"PD 456\", \"PD 462\", \"PD 466\", \"PD 483\", \"PD 491\", \"PD 535\",\n",
    "    \"PD 536\", \"PD 537\", \"PD 546\", \"PD 549\", \"PD 555\", \"PD 599\", \"PD 601\", \"PD 609\", \"PD 610\", \"PD 615\",\n",
    "    \"PD 622\", \"PD 623\", \"PD 631\", \"PD 632\", \"PD 636\", \"PD 637\", \"PD 645\", \"PD 650\", \"PD 651\", \"PD 661\",\n",
    "    \"PD 678\", \"PD 684\", \"PD 686\", \"PD 687\", \"PD 690\", \"PD 691\", \"PD 692\", \"PD 700\", \"PD 704\", \"PD 705\",\n",
    "    \"PD 707\", \"PD 711\", \"PD 712\", \"PD 713\", \"PD 714\", \"PD 715\", \"PD 720\", \"PD 723\", \"PD 734\", \"PD 737\", \n",
    "    \"PD 744\", \"PD 749\", \"PD 764\", \"PD 771\", \"PD 774\", \"PD 777\", \"PD 783\", \"PD 786\", \"PD 788\", \"PD 797\",\n",
    "    \"PD 803\", \"PD 817\", \"PD 826\", \"PD 827\", \"PD 828\", \"PD 831\", \"PD 832\", \"PD 833\", \"PD 836\", \"PD 838\",\n",
    "    \"PD 839\", \"PD 840\", \"PD 849\", \"PD 853\", \"PD 854\", \"PD 855\", \"PD 858\", \"PD 865\", \"PD 866\", \"PD 869\",\n",
    "    \"PD 873\", \"PD 879\", \"PD 885\", \"PD 888\", \"PD 893\", \"PD 896\", \"PD 897\", \"PD 911\", \"PD 913\", \"PD 917\",\n",
    "    \"PD 918\", \"PD 921\", \"PD 928\", \"PD 929\", \"PD 930\", \"PD 937\", \"PD 939\", \"PD 945\", \"PD 948\", \"PD 955\",\n",
    "    \"PD 963\", \"PD 976\", \"PD 984\", \"PD 985\", \"PD 986\", \"PD 999\", \"PD 1001\", \"PD 1004\", \"PD 1008\", \"PD 1009\",\n",
    "    \"PD 1013\", \"PD 1017\", \"PD 1024\", \"PD 1027\", \"PD 1043\", \"PD 1046\", \"PD 1064\", \"PD 1068\", \"PD 1084\", \"PD 1095\",\n",
    "    \"PD 1101\", \"PD 1103\", \"PD 1120\", \"PD 1131\", \"PD 1141\", \"PD 1145\", \"PD 1169\", \"PD 1185\", \"PD 1189\", \"PD 1197\",\n",
    "    \"PD 1206\", \"PD 1215\", \"PD 1220\", \"PD 1237\", \"PD 1259\", \"PD 1262\", \"PD 1270\", \"PD 1276\", \"PD 1287\", \"PD 1289\",\n",
    "    \"PD 1292\", \"PD 1294\", \"PD 1304\", \"PD 1305\", \"PD 1308\", \"PD 1313\", \"PD 1319\", \"PD 1327\", \"PD 1332\", \"PD 1335\",\n",
    "    \"PD 1340\", \"PD 1345\", \"PD 1352\", \"PD 1357\", \"PD 1358\", \"PD 1364\", \"PD 1370\", \"PD 1373\", \"PD 1374\", \"PD 1379\",\n",
    "    \"PD 1399\", \"PD 1401\", \"PD 1419\", \"PD 1423\", \"PD 1429\", \"PD 1430\", \"PD 1439\", \"PD 1444\", \"PD 1468\", \"PD 1473\",\n",
    "    \"PD 1481\", \"PD 1484\", \"PD 1492\", \"PD 1501\", \"PD 1505\", \"PD 1513\", \"PD 1514\", \"PD 1520\", \"PD 1535\", \"PD 1536\",\n",
    "    \"PD 1540\", \"PD 1541\", \"PD 1542\", \"PD 1543\", \"PD 1548\", \"PD 1550\", \"PD 1552\", \"PD 1553\", \"PD 1559\", \"PD 1568\", \n",
    "    \"PD 1569\", \"PD 1582\", \"PD 1584\"\n",
    "]\n",
    "\n",
    "# Filter the DataFrame for high-density zoning\n",
    "df_high_density = df[df['ZONE_CLASS'].isin(high_density_zones)]\n",
    "\n",
    "# Save filtered data, ensuring PIN remains a string\n",
    "output_path = \"C:/Users/kaur6/Downloads/Urban Analytics/filtered_high_density_zoning.csv\"\n",
    "df_high_density.to_csv(output_path, index=False)\n",
    "\n",
    "# Preview the filtered data\n",
    "print(df_high_density.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c02d573-10ec-4586-bdf8-683044b2dd0d",
   "metadata": {},
   "source": [
    "## Plotting PINs near bus stops and train stations that fall in high density areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c66c963-986b-4540-b37f-9a54526acf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map saved to C:/Users/kaur6/Downloads/Urban Analytics/pins_connected_comm_map.html\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "file_path = \"C:/Users/kaur6/Downloads/Urban Analytics/filtered_high_density_zoning.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure required columns exist\n",
    "assert {'pin', 'latitude', 'longitude'}.issubset(df.columns), \"CSV must contain 'pin', 'latitude', 'longitude' columns\"\n",
    "\n",
    "# Convert PIN to string\n",
    "df['pin'] = df['pin'].astype(str)\n",
    "\n",
    "# Create a Folium map centered on the dataset\n",
    "map_center = [df[\"latitude\"].mean(), df[\"longitude\"].mean()]\n",
    "m = folium.Map(location=map_center, zoom_start=11, tiles=\"CartoDB positron\")\n",
    "\n",
    "# Create cluster markers with PIN popups\n",
    "marker_data = [\n",
    "    [row[\"latitude\"], row[\"longitude\"], f\"PIN: {row['pin']}\"] for _, row in df.iterrows()\n",
    "]\n",
    "\n",
    "# Attach data to FastMarkerCluster\n",
    "FastMarkerCluster(\n",
    "    marker_data,\n",
    "    callback=\"\"\"\n",
    "    function (row) {\n",
    "        var marker = L.marker(new L.LatLng(row[0], row[1]));\n",
    "        marker.bindPopup(row[2]); \n",
    "        return marker;\n",
    "    }\n",
    "    \"\"\"\n",
    ").add_to(m)\n",
    "\n",
    "# Save to an HTML file\n",
    "map_file = \"C:/Users/kaur6/Downloads/Urban Analytics/pins_connected_comm_map.html\"\n",
    "m.save(map_file)\n",
    "print(f\"Map saved to {map_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd5cb9ad-0a37-47a7-bd7f-3aecd762843f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test HeatMap saved successfully at: C:/Users/kaur6/Downloads/Urban Analytics/test_heatmap.html\n"
     ]
    }
   ],
   "source": [
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "# Test with a minimal dataset\n",
    "test_data = [\n",
    "    [41.829544, -87.643993],\n",
    "    [41.949544, -87.665653],\n",
    "    [41.910595, -87.630613],\n",
    "    [41.854619, -87.682744],\n",
    "    [41.951253, -87.656356]\n",
    "]\n",
    "\n",
    "# Create a base map\n",
    "m = folium.Map(location=[41.88, -87.63], zoom_start=10, tiles=\"cartodbpositron\")\n",
    "\n",
    "# Apply HeatMap with test data\n",
    "HeatMap(test_data, name=\"Test HeatMap\", radius=8).add_to(m)\n",
    "\n",
    "# Save the map\n",
    "map_file = \"C:/Users/kaur6/Downloads/Urban Analytics/test_heatmap.html\"\n",
    "m.save(map_file)\n",
    "\n",
    "print(f\"Test HeatMap saved successfully at: {map_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0684808-dd19-4422-9c52-5b13d2e68881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c808ca-ac75-4240-8a56-18a9116b9636",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (geo_env)",
   "language": "python",
   "name": "geo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
