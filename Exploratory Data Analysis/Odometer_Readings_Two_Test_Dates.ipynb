{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4fa8063",
   "metadata": {},
   "source": [
    "## Odometer_Readings_Two_Test_Dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2d9d93",
   "metadata": {},
   "source": [
    "### make two different columns for the vehicle like two odometer readings for two different test dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3aa85b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c3b7412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vin</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>odometer</th>\n",
       "      <th>test_date</th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>my</th>\n",
       "      <th>purchase_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WBAEV33452KL68783</td>\n",
       "      <td>60655</td>\n",
       "      <td>125000</td>\n",
       "      <td>6/1/2020</td>\n",
       "      <td>BMW</td>\n",
       "      <td>3 Series</td>\n",
       "      <td>2002</td>\n",
       "      <td>5/1/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1GBFG15R6Y1100200</td>\n",
       "      <td>60632</td>\n",
       "      <td>206000</td>\n",
       "      <td>6/1/2020</td>\n",
       "      <td>CHEV</td>\n",
       "      <td>Express Cargo</td>\n",
       "      <td>2000</td>\n",
       "      <td>5/21/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1GCDT136548185796</td>\n",
       "      <td>60501</td>\n",
       "      <td>109000</td>\n",
       "      <td>6/1/2020</td>\n",
       "      <td>CHEV</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>2004</td>\n",
       "      <td>6/18/2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2GKALMEK0C6364495</td>\n",
       "      <td>60453</td>\n",
       "      <td>80000</td>\n",
       "      <td>6/1/2020</td>\n",
       "      <td>GMC</td>\n",
       "      <td>Terrain</td>\n",
       "      <td>2012</td>\n",
       "      <td>4/26/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1HGCG1652YA094701</td>\n",
       "      <td>60459</td>\n",
       "      <td>167000</td>\n",
       "      <td>6/1/2020</td>\n",
       "      <td>HOND</td>\n",
       "      <td>Accord</td>\n",
       "      <td>2000</td>\n",
       "      <td>7/19/2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 vin  zipcode  odometer test_date  make          model    my  \\\n",
       "0  WBAEV33452KL68783    60655    125000  6/1/2020  BMW        3 Series  2002   \n",
       "1  1GBFG15R6Y1100200    60632    206000  6/1/2020  CHEV  Express Cargo  2000   \n",
       "2  1GCDT136548185796    60501    109000  6/1/2020  CHEV       Colorado  2004   \n",
       "3  2GKALMEK0C6364495    60453     80000  6/1/2020  GMC         Terrain  2012   \n",
       "4  1HGCG1652YA094701    60459    167000  6/1/2020  HOND         Accord  2000   \n",
       "\n",
       "  purchase_date  \n",
       "0      5/1/2021  \n",
       "1     5/21/2017  \n",
       "2     6/18/2013  \n",
       "3     4/26/2018  \n",
       "4     7/19/2014  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Extracting ZIP Code Prefixes & Matching with VINs.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb403d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8338418, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "442644fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8338418 entries, 0 to 8338417\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Dtype \n",
      "---  ------         ----- \n",
      " 0   vin            object\n",
      " 1   zipcode        int64 \n",
      " 2   odometer       int64 \n",
      " 3   test_date      object\n",
      " 4   make           object\n",
      " 5   model          object\n",
      " 6   my             int64 \n",
      " 7   purchase_date  object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 508.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "913ab23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vin              0\n",
       "zipcode          0\n",
       "odometer         0\n",
       "test_date        0\n",
       "make             0\n",
       "model            0\n",
       "my               0\n",
       "purchase_date    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d6f84ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duplicate rows: 37406\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vin</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>odometer</th>\n",
       "      <th>test_date</th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>my</th>\n",
       "      <th>purchase_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>2G4WS52J351137092</td>\n",
       "      <td>60433</td>\n",
       "      <td>0</td>\n",
       "      <td>6/1/2020</td>\n",
       "      <td>BUIC</td>\n",
       "      <td>Century</td>\n",
       "      <td>2005</td>\n",
       "      <td>12/1/2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>5Y2SL65816Z435471</td>\n",
       "      <td>60543</td>\n",
       "      <td>0</td>\n",
       "      <td>6/1/2020</td>\n",
       "      <td>PONT</td>\n",
       "      <td>Vibe</td>\n",
       "      <td>2006</td>\n",
       "      <td>7/14/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>JTKKUPB46E1042219</td>\n",
       "      <td>60608</td>\n",
       "      <td>23000</td>\n",
       "      <td>6/1/2020</td>\n",
       "      <td>TOYT</td>\n",
       "      <td>xD</td>\n",
       "      <td>2014</td>\n",
       "      <td>4/9/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2487</th>\n",
       "      <td>1G1PF5SCXC7346028</td>\n",
       "      <td>60185</td>\n",
       "      <td>132000</td>\n",
       "      <td>6/1/2020</td>\n",
       "      <td>CHEV</td>\n",
       "      <td>Cruze</td>\n",
       "      <td>2012</td>\n",
       "      <td>3/14/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>1G4PP5SKXE4182274</td>\n",
       "      <td>60403</td>\n",
       "      <td>19000</td>\n",
       "      <td>6/1/2020</td>\n",
       "      <td>BUIC</td>\n",
       "      <td>Verano</td>\n",
       "      <td>2014</td>\n",
       "      <td>5/9/2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    vin  zipcode  odometer test_date  make    model    my  \\\n",
       "423   2G4WS52J351137092    60433         0  6/1/2020  BUIC  Century  2005   \n",
       "463   5Y2SL65816Z435471    60543         0  6/1/2020  PONT     Vibe  2006   \n",
       "581   JTKKUPB46E1042219    60608     23000  6/1/2020  TOYT       xD  2014   \n",
       "2487  1G1PF5SCXC7346028    60185    132000  6/1/2020  CHEV    Cruze  2012   \n",
       "2716  1G4PP5SKXE4182274    60403     19000  6/1/2020  BUIC   Verano  2014   \n",
       "\n",
       "     purchase_date  \n",
       "423      12/1/2005  \n",
       "463      7/14/2018  \n",
       "581       4/9/2014  \n",
       "2487     3/14/2018  \n",
       "2716      5/9/2016  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find duplicate rows\n",
    "duplicates = df[df.duplicated()]\n",
    "print(\"Total duplicate rows:\", len(duplicates))\n",
    "\n",
    "# Display duplicate rows\n",
    "duplicates.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0806faa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    vin  zipcode  odometer test_date  make    model    my  \\\n",
      "423   2G4WS52J351137092    60433         0  6/1/2020  BUIC  Century  2005   \n",
      "463   5Y2SL65816Z435471    60543         0  6/1/2020  PONT     Vibe  2006   \n",
      "581   JTKKUPB46E1042219    60608     23000  6/1/2020  TOYT       xD  2014   \n",
      "2487  1G1PF5SCXC7346028    60185    132000  6/1/2020  CHEV    Cruze  2012   \n",
      "2716  1G4PP5SKXE4182274    60403     19000  6/1/2020  BUIC   Verano  2014   \n",
      "\n",
      "     purchase_date  \n",
      "423      12/1/2005  \n",
      "463      7/14/2018  \n",
      "581       4/9/2014  \n",
      "2487     3/14/2018  \n",
      "2716      5/9/2016  \n",
      "Are all columns identical in duplicates?\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Display the first few duplicate rows\n",
    "print(duplicates.head())\n",
    "\n",
    "# Check if all columns are identical for duplicates\n",
    "print(\"Are all columns identical in duplicates?\")\n",
    "print(df[df.duplicated()].equals(df[df.duplicated(keep=False)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7918b9",
   "metadata": {},
   "source": [
    "The analysis first focused on identifying duplicate records within the dataset. By inspecting duplicates, it was determined that not all columns were identical in the duplicate entries. This suggests that some records might have inconsistencies or variations in specific attributes such as odometer readings or ZIP codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "276ac5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial duplicates based on 'vin' and 'test_date':\n",
      "                       vin  zipcode  odometer  test_date  make        model  \\\n",
      "37       5J6RE4H34AL051901    60629     60000   6/1/2020  HOND         CR-V   \n",
      "62       4T1BG22KXYU650856    60164      1000   6/1/2020  TOYT        Camry   \n",
      "97       JTKKUPB46E1042219    60608     23000   6/1/2020  TOYT           xD   \n",
      "407      2G4WS52J351137092    60433         0   6/1/2020  BUIC      Century   \n",
      "408      5TDZA23CX6S505619    60645    265000   6/1/2020  TOYT       Sienna   \n",
      "...                    ...      ...       ...        ...   ...          ...   \n",
      "8338329  1NXBU40EX9Z030480    60626    189000  8/31/2024  TOYT      Corolla   \n",
      "8338333  1G1PH5S97B7135866    60643     54000  8/31/2024  CHEV        Cruze   \n",
      "8338357  1GNEK13T61J301869    60123    201000  8/31/2024  CHEV        Tahoe   \n",
      "8338369  2GNALDEK9D6402195    60608    118000  8/31/2024  CHEV      Equinox   \n",
      "8338410  3GTEK13358G235173    60099    211000  8/31/2024  GMC   Sierra 1500   \n",
      "\n",
      "           my purchase_date  \n",
      "37       2010      5/8/2010  \n",
      "62       2000      8/1/2020  \n",
      "97       2014      4/9/2014  \n",
      "407      2005     12/1/2005  \n",
      "408      2006     5/30/2018  \n",
      "...       ...           ...  \n",
      "8338329  2009      8/5/2023  \n",
      "8338333  2011     8/31/2023  \n",
      "8338357  2001     4/22/2023  \n",
      "8338369  2013     6/29/2013  \n",
      "8338410  2008     8/27/2020  \n",
      "\n",
      "[254801 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates based on 'vin' and 'test_date'\n",
    "partial_duplicates = df[df.duplicated(subset=['vin', 'test_date'], keep=False)]\n",
    "print(\"Partial duplicates based on 'vin' and 'test_date':\")\n",
    "print(partial_duplicates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d09a5be",
   "metadata": {},
   "source": [
    "To refine the duplicate analysis, the dataset was checked for partial duplicates based on `vin` (Vehicle Identification Number) and `test_date`. This step revealed that a significant number of records had the same VIN and test date but potentially differed in other attributes. This highlights data redundancy or potential errors in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52a7742f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   vin  test_date  zipcode  odometer  make   model    my  \\\n",
      "0  10000000000003412WI   9/8/2020    60505  114000.0  CHEV          1999   \n",
      "1  10000000000005614WI  8/26/2024    60174  115000.0  FORD          2005   \n",
      "2  10000000000005641WI  11/5/2021    60041   99000.0  FORD          2005   \n",
      "3    107HA18N92J225350  1/16/2020    60804  216000.0  DODG          2002   \n",
      "4     11ND52J43M623642  8/10/2021    60617  156000.0  CHEV  MAL     2003   \n",
      "\n",
      "  purchase_date  \n",
      "0      3/4/2011  \n",
      "1     9/15/2023  \n",
      "2     10/2/2018  \n",
      "3    10/15/2018  \n",
      "4      1/1/1900  \n"
     ]
    }
   ],
   "source": [
    "# Aggregate duplicate rows by grouping by 'vin' and 'test_date'\n",
    "df = df.groupby(['vin', 'test_date'], as_index=False).agg({\n",
    "    'zipcode': 'first',       \n",
    "    'odometer': 'mean',       \n",
    "    'make': 'first',         \n",
    "    'model': 'first',         \n",
    "    'my': 'first',            \n",
    "    'purchase_date': 'min'    \n",
    "})\n",
    "\n",
    "# Display results after aggregation\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87c464a",
   "metadata": {},
   "source": [
    "To resolve duplicate entries, an aggregation method was applied. The data was grouped by `vin` and `test_date`, ensuring that for each unique combination, key attributes were retained in a structured manner:\n",
    "- **Zipcode**: The first occurrence was kept.\n",
    "- **Odometer Reading**: The average value was taken.\n",
    "- **Make, Model, and Model Year**: The first occurrence was retained.\n",
    "- **Purchase Date**: The earliest recorded purchase date was selected.\n",
    "\n",
    "This aggregation approach ensures a more consistent and reliable dataset while removing redundancy, ultimately improving data quality for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96cce3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "remaining_duplicates = df[df.duplicated(subset=['vin', 'test_date'])]\n",
    "print(f\"Remaining duplicate rows: {len(remaining_duplicates)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38248a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    8.207797e+06\n",
      "mean     1.012595e+05\n",
      "std      6.113666e+04\n",
      "min      0.000000e+00\n",
      "25%      5.600000e+04\n",
      "50%      9.200000e+04\n",
      "75%      1.390000e+05\n",
      "max      9.990000e+05\n",
      "Name: odometer, dtype: float64\n",
      "['CHEV' 'FORD' 'DODG' 'ACUR' 'ALFA' 'HOND' 'AC  ' 'HYUN' 'CHRY' 'CHRS'\n",
      " 'DESO' 'Chry' 'JEEP' 'JENS' 'Jeep' 'Dodg' 'RAM ' 'IM92' 'Ram' 'DAIM'\n",
      " 'RAM' 'SUBA' 'Ford' 'TRAP' 'HZ58' 'GX11' 'THMH' 'AXS1' 'UTIM' 'GW81'\n",
      " 'ID66' 'READ' 'HV11' 'MIBR' 'GA77' 'MBMB' 'IR13' 'STAO' 'GU01' 'ELKC'\n",
      " 'SRCR' 'ELKD' 'STR1' 'DMND' 'CHAM' 'GEN ' 'STTT' 'IP44' 'WORL' 'SENA'\n",
      " 'GOSH' 'IQ29' 'SCSL' 'COAM' 'CRFT' 'COAH' 'FOUW' 'MNAC' 'RKPT' 'THOR'\n",
      " 'SCSQ' 'WINN' 'MJST' 'MIWI' 'FD83' 'GB65' 'CHAT' 'IM73' 'MTMH' 'FIAT'\n",
      " 'GMC ' 'TOYT' 'ENGF' 'BMW ' 'NISS' 'FRHT' 'Chev' 'HP10' 'CADI' 'PONT'\n",
      " 'BUIC' 'Pont' 'OLDS' 'HF49' 'MITS' 'STRN' 'SATU' 'ICRP' 'ZZ19' 'STPR'\n",
      " 'FRDE' 'BYBR' 'TTBS' 'FZ76' 'GLF ' 'GZ05' 'IF75' 'IC61' 'ISU ' 'GMC'\n",
      " 'INTL' 'HV03' 'GEO ' 'CHBS' 'HIND' 'AMER' 'LEXS' 'LINC' 'MERC' 'MERB'\n",
      " 'DATS' 'TOYO' 'SUZI' 'PLYM' 'IH08' 'MORG' 'VOLK' 'VW  ' 'VOLV' 'MAZD'\n",
      " 'DAIH' 'IC96' 'EGIL' 'AVTI' 'IQ28' 'MERZ' 'SUZU' 'TRIU' 'STU ' 'DAEW'\n",
      " 'IL65' 'CRDO' 'GB36' 'RDTR' 'WNTG' 'PLEM' 'WINO' 'REVH' 'SAA ' 'Satu'\n",
      " 'KIA ' 'SCIO' 'Niss' 'INFI' 'EAGL' 'FO81' 'ISU' 'BMW' 'KARM' 'VPGP'\n",
      " 'MVVN' 'MOLY' 'MV1 ' 'AGEN' 'IL45' 'HI03' 'AMGM' 'WKCC' 'IO38' 'WORH'\n",
      " 'WRKH' 'ASTO' 'SHEB' 'HUMM' 'IH32' 'Hyun' 'SAAB' 'AUST' 'KIA' 'TESL'\n",
      " 'AUDI' 'ASMB' 'IX44' 'MERK' 'PRIM' 'IH57' 'HV57' 'GENI' 'Kia' 'ASMD'\n",
      " 'JAGU' 'LNDR' 'HD22' 'LAND' 'ROV ' 'MCLR' 'MCLA' 'MCLP' 'ZC35' 'ROL '\n",
      " 'ROLC' 'BENT' 'LOTU' 'FZ63' 'BUGA' 'SPNR' 'SPNT' 'IN12' 'IC51' 'MAYB'\n",
      " 'MZMH' 'GY28' 'SMRT' 'SMFT' 'MNNI' 'FE86' 'MINI' 'COOP' 'GN62' 'FE88'\n",
      " 'FE36' 'PORS' 'IA30' 'FSKR' 'FISK' 'SAA' 'VOWH' 'LAMO' 'MASE' 'ALRM'\n",
      " 'IP08' 'FERR']\n"
     ]
    }
   ],
   "source": [
    "# Check descriptive statistics for numerical columns\n",
    "print(df['odometer'].describe())\n",
    "\n",
    "# Check unique values for categorical columns\n",
    "print(df['make'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2527eab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "vin              0\n",
      "test_date        0\n",
      "zipcode          0\n",
      "odometer         0\n",
      "make             0\n",
      "model            0\n",
      "my               0\n",
      "purchase_date    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a51af16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique years in the dataset: [2020 2024 2021 2023]\n"
     ]
    }
   ],
   "source": [
    "# Ensure 'test_date' is in datetime format\n",
    "\n",
    "df['test_date'] = pd.to_datetime(df['test_date'])\n",
    "\n",
    "# Extract unique years\n",
    "unique_years = df['test_date'].dt.year.unique()\n",
    "print(f\"Unique years in the dataset: {unique_years}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53ffe08",
   "metadata": {},
   "source": [
    "To analyze trends over time, the `test_date` column was converted to datetime format, and the unique years were extracted. The dataset contained records from the years **2020, 2021, 2023, and 2024**. This information is useful for time-based analysis, such as identifying trends in vehicle inspections over different years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d30dff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2020-09-08T00:00:00.000000000', '2024-08-26T00:00:00.000000000',\n",
       "       '2021-11-05T00:00:00.000000000', ...,\n",
       "       '2021-01-18T00:00:00.000000000', '2024-05-05T00:00:00.000000000',\n",
       "       '2020-11-27T00:00:00.000000000'], dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['test_date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9a2f586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'test_date' to datetime format for consistency\n",
    "df['test_date'] = pd.to_datetime(df['test_date'])\n",
    "\n",
    "# Define two specific test dates\n",
    "date1 = '2020-09-08T00:00:00.000000000'\n",
    "date2 = '2021-11-05T00:00:00.000000000'\n",
    "\n",
    "# Filter data for these two test dates\n",
    "df_date1 = df[df['test_date'] == date1][['vin', 'odometer']].rename(columns={'odometer': 'odometer_date1'})\n",
    "df_date2 = df[df['test_date'] == date2][['vin', 'odometer']].rename(columns={'odometer': 'odometer_date2'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f15c7d",
   "metadata": {},
   "source": [
    "To analyze vehicle odometer readings over time, the dataset was filtered for two specific test dates: **September 8, 2020, and November 5, 2021**. The odometer readings for these dates were extracted for each **VIN (Vehicle Identification Number)**, creating two separate datasets: \n",
    "- `df_date1` containing VINs and their odometer readings for the first test date.\n",
    "- `df_date2` containing VINs and their odometer readings for the second test date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8134161b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [vin, odometer_date1, odometer_date2]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Merge the two DataFrames on 'vin'\n",
    "df_combined = pd.merge(df_date1, df_date2, on='vin', how='inner')\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(df_combined.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82723809",
   "metadata": {},
   "source": [
    "The two datasets were merged based on `vin` to compare odometer readings across these dates. However, the merged DataFrame resulted in an **empty DataFrame**, indicating that **no common VINs existed between the two test dates**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4201009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in df_date1 (date1): 9636\n",
      "Rows in df_date2 (date2): 6915\n"
     ]
    }
   ],
   "source": [
    "# Check the number of rows in df_date1 and df_date2\n",
    "print(f\"Rows in df_date1 (date1): {len(df_date1)}\")\n",
    "print(f\"Rows in df_date2 (date2): {len(df_date2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91c5d5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common VINs: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for common VINs between df_date1 and df_date2\n",
    "common_vins = set(df_date1['vin']).intersection(set(df_date2['vin']))\n",
    "print(f\"Number of common VINs: {len(common_vins)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438d7b55",
   "metadata": {},
   "source": [
    "A check was performed to find common VINs between the two test dates. The result showed **zero common VINs**, meaning that no vehicle appeared in both test dates in this dataset. This could indicate that vehicles were not tested repeatedly or that there are inconsistencies in the dataset that need further exploration.\n",
    "\n",
    "These findings suggest that further data validation and additional filtering criteria might be necessary to track vehicles over multiple test dates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84df5dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize 'vin' column by stripping spaces and converting to uppercase\n",
    "df['vin'] = df['vin'].str.strip().str.upper()\n",
    "\n",
    "# Re-create df_date1 and df_date2 after standardizing\n",
    "df_date1 = df[df['test_date'] == date1][['vin', 'odometer']].rename(columns={'odometer': 'odometer_date1'})\n",
    "df_date2 = df[df['test_date'] == date2][['vin', 'odometer']].rename(columns={'odometer': 'odometer_date2'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36ac96ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common VINs after standardization: 0\n"
     ]
    }
   ],
   "source": [
    "common_vins = set(df_date1['vin']).intersection(set(df_date2['vin']))\n",
    "print(f\"Number of common VINs after standardization: {len(common_vins)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc441aa0",
   "metadata": {},
   "source": [
    "To ensure consistency in VIN formatting, the `vin` column was standardized by:\n",
    "- Stripping any leading or trailing spaces.\n",
    "- Converting all values to uppercase.\n",
    "\n",
    "After applying this standardization, the dataset was re-filtered to recreate `df_date1` and `df_date2`, containing VINs and odometer readings for the two selected test dates. However, when checking for common VINs between these two dates, the result **remained zero**. This suggests that the absence of common VINs was not due to formatting inconsistencies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5525d7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of date pairs with overlaps: 447946\n",
      "Sample overlaps:\n",
      "2020-09-08T00:00:00.000000000 and 2024-08-26T00:00:00.000000000: 46 common VINs\n",
      "2020-09-08T00:00:00.000000000 and 2021-08-10T00:00:00.000000000: 6 common VINs\n",
      "2020-09-08T00:00:00.000000000 and 2023-06-29T00:00:00.000000000: 4 common VINs\n",
      "2020-09-08T00:00:00.000000000 and 2020-11-09T00:00:00.000000000: 5 common VINs\n",
      "2020-09-08T00:00:00.000000000 and 2020-11-07T00:00:00.000000000: 1 common VINs\n"
     ]
    }
   ],
   "source": [
    "# Get all unique test dates (remove the [:100] limitation)\n",
    "unique_test_dates = df['test_date'].unique()\n",
    "\n",
    "# Create a dictionary to store VINs for each test date\n",
    "date_vin_dict = {date: set(df[df['test_date'] == date]['vin']) for date in unique_test_dates}\n",
    "\n",
    "# Create a dictionary to store overlaps\n",
    "overlap_dict = {}\n",
    "\n",
    "# Compute overlaps\n",
    "for i, date1 in enumerate(unique_test_dates):\n",
    "    for date2 in unique_test_dates[i+1:]:\n",
    "        common_vins = len(date_vin_dict[date1] & date_vin_dict[date2])\n",
    "        if common_vins > 0:\n",
    "            overlap_dict[(date1, date2)] = common_vins\n",
    "\n",
    "# Display results\n",
    "print(f\"Number of date pairs with overlaps: {len(overlap_dict)}\")\n",
    "print(\"Sample overlaps:\")\n",
    "for (date1, date2), count in list(overlap_dict.items())[:5]:\n",
    "    print(f\"{date1} and {date2}: {count} common VINs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657ed5ae",
   "metadata": {},
   "source": [
    "To further investigate whether vehicles were tested on multiple dates, a broader approach was taken:\n",
    "- All unique test dates in the dataset were identified.\n",
    "- A dictionary was created to store VINs associated with each test date.\n",
    "- Overlaps were computed between every pair of test dates by checking common VINs.\n",
    "\n",
    "The results showed that there were **447,946 test date pairs with overlapping VINs**, indicating that many vehicles did undergo multiple tests, just not specifically on the two originally chosen test dates.\n",
    "\n",
    "Some sample overlaps between test dates were displayed, showing instances where vehicles had common VINs across different dates. For example:\n",
    "- **46 common VINs** between **2020-09-08 and 2024-08-26**.\n",
    "- **6 common VINs** between **2020-09-08 and 2021-08-07**.\n",
    "- Other test date pairs with small but significant overlaps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9caca994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected test dates\n",
    "date1 = '2020-09-08'\n",
    "date2 = '2024-08-26'\n",
    "\n",
    "# Filter data for the two selected test dates\n",
    "df_date1 = df[df['test_date'] == date1][['vin', 'odometer']].rename(columns={'odometer': 'odometer_date1'})\n",
    "df_date2 = df[df['test_date'] == date2][['vin', 'odometer']].rename(columns={'odometer': 'odometer_date2'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60799261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 vin  odometer_date1  odometer_date2\n",
      "0  1C4BJWEG7GL337305         39000.0         73000.0\n",
      "1  1C4NJCBB2CD610286         70000.0        103000.0\n",
      "2  1C4RJFCG0CC345855         65000.0         91000.0\n",
      "3  1FA6P0HD3E5378424         93000.0        108000.0\n",
      "4  1G11J5SX3EF225275         25000.0         33000.0\n"
     ]
    }
   ],
   "source": [
    "# Merge the two DataFrames on 'vin'\n",
    "df_combined = pd.merge(df_date1, df_date2, on='vin', how='inner')\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(df_combined.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2212bf9",
   "metadata": {},
   "source": [
    "#### Key Observations:\n",
    "- All vehicles showed an **increase in odometer readings**, confirming expected mileage accumulation.\n",
    "- This comparison enables further analysis, such as:\n",
    "  - **Estimating annual vehicle usage**\n",
    "  - **Identifying anomalies or potential odometer rollbacks**\n",
    "  - **Understanding vehicle longevity and wear patterns**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b059f099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 vin  odometer_date1  odometer_date2  mileage_difference  \\\n",
      "0  1C4BJWEG7GL337305         39000.0         73000.0             34000.0   \n",
      "1  1C4NJCBB2CD610286         70000.0        103000.0             33000.0   \n",
      "2  1C4RJFCG0CC345855         65000.0         91000.0             26000.0   \n",
      "3  1FA6P0HD3E5378424         93000.0        108000.0             15000.0   \n",
      "4  1G11J5SX3EF225275         25000.0         33000.0              8000.0   \n",
      "\n",
      "   test_date1  test_date2  \n",
      "0  2020-09-08  2024-08-26  \n",
      "1  2020-09-08  2024-08-26  \n",
      "2  2020-09-08  2024-08-26  \n",
      "3  2020-09-08  2024-08-26  \n",
      "4  2020-09-08  2024-08-26  \n"
     ]
    }
   ],
   "source": [
    "# Add columns for the selected test dates\n",
    "df_combined['test_date1'] = date1\n",
    "df_combined['test_date2'] = date2\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(df_combined.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8a2a793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 vin  mileage_difference\n",
      "0  1C4BJWEG7GL337305             34000.0\n",
      "1  1C4NJCBB2CD610286             33000.0\n",
      "2  1C4RJFCG0CC345855             26000.0\n",
      "3  1FA6P0HD3E5378424             15000.0\n",
      "4  1G11J5SX3EF225275              8000.0\n"
     ]
    }
   ],
   "source": [
    "df_combined['mileage_difference'] = df_combined['odometer_date2'] - df_combined['odometer_date1']\n",
    "print(df_combined[['vin', 'mileage_difference']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265287c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
