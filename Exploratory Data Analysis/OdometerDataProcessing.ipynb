{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baba34d1-96fc-435f-8a98-53cea10b8502",
   "metadata": {},
   "source": [
    "### Merging all the files in individual folders in Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a865d12-9c84-4e71-bd65-179b054f196d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the main directory containing year folders\n",
    "main_dir = \"C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full\"\n",
    "\n",
    "# List of year folders\n",
    "year_folders = [\"illinois_2020\", \"illinois_2021\", \"illinois_2023\", \"illinois_2024\"]\n",
    "merged_files = []\n",
    "\n",
    "for year in year_folders:\n",
    "    year_path = os.path.join(main_dir, year)\n",
    "    all_files = [os.path.join(year_path, f) for f in os.listdir(year_path) if f.endswith(\".csv\")]\n",
    "    \n",
    "    # Merge all CSVs within the year folder\n",
    "    df_list = [pd.read_csv(f) for f in all_files]\n",
    "    merged_df = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    # Save merged file in the same folder\n",
    "    merged_filename = os.path.join(year_path, f\"{year}.csv\")\n",
    "    merged_df.to_csv(merged_filename, index=False)\n",
    "    \n",
    "    merged_files.append(merged_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546c6244-f8b9-46b1-9293-fa7c369c4dd6",
   "metadata": {},
   "source": [
    "### Merging those 4 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5323a71a-116c-43dc-bada-4dbb14c223e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all yearly merged CSVs into one final file\n",
    "final_df_list = [pd.read_csv(f) for f in merged_files]\n",
    "final_df = pd.concat(final_df_list, ignore_index=True)\n",
    "\n",
    "# Save the final merged CSV\n",
    "final_output = os.path.join(main_dir, \"merged_all_years.csv\")\n",
    "final_df.to_csv(final_output, index=False)\n",
    "\n",
    "print(\"Merging completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f62ad4d-ad2e-4432-88d9-2492b9606779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd826cd2-6bcb-4005-8b1d-75a0d7fc4bae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b1c91f6-7aa7-461d-a0ce-ca7530e76b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV with models and years has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "# Load the model names and years from the CSVs\n",
    "with open('C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/unique_models.csv', 'r') as f:\n",
    "    model_names = f.read().splitlines()\n",
    "\n",
    "with open('C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/unique_my.csv', 'r') as f:\n",
    "    model_years = f.read().splitlines()\n",
    "\n",
    "# Prepare a list to store the combined model-year pairs\n",
    "combined_data = []\n",
    "\n",
    "# Loop through each model name and combine with each year\n",
    "for model in model_names:\n",
    "    for year in model_years:\n",
    "        combined_data.append([model, year])\n",
    "\n",
    "# Write the combined data into a new CSV file\n",
    "with open('C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/combined_model_year.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Model', 'Year'])  # Write the header\n",
    "    writer.writerows(combined_data)  # Write the data rows\n",
    "\n",
    "print(\"CSV with models and years has been created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54544d38-29ef-4fb1-9e1a-367ec5ae1e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3838f25-c5d8-425c-b9cd-608cba6cf873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging complete! The final file is saved as 'ninja_api_results_full.csv'.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "# Get all CSV file paths (modify the path if needed)\n",
    "csv_files = glob.glob(\"C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/*.csv\")  # Update path accordingly\n",
    "\n",
    "# Read and merge CSV files\n",
    "df_list = [pd.read_csv(file) for file in csv_files]\n",
    "merged_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Save to a new CSV file\n",
    "merged_df.to_csv(\"C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/ninja_api_results_full.csv\", index=False)\n",
    "\n",
    "print(\"Merging complete! The final file is saved as 'ninja_api_results_full.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4dd0f6c-3ba1-461b-91cc-70781f30af56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 458 models to C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/models_with_no_mpg_data.csv\n",
      "Count of models with 'No data found' for all 32 years: 458\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/ninja_api_results_full.csv')\n",
    "\n",
    "# Group by 'Model' and check if all values in 'Combination MPG' are 'No data found'\n",
    "filtered_models = df.groupby('Model')['CombinationMPG'].apply(lambda x: all(x == 'No data found'))\n",
    "\n",
    "# Get the model names that satisfy the condition\n",
    "models_with_no_mpg_data = filtered_models[filtered_models].index.tolist()\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "output_df = pd.DataFrame(models_with_no_mpg_data, columns=['Model'])\n",
    "\n",
    "# Save to a CSV file\n",
    "output_csv_path = 'C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/models_with_no_mpg_data.csv'\n",
    "output_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Print confirmation message\n",
    "print(f\"Saved {len(models_with_no_mpg_data)} models to {output_csv_path}\")\n",
    "print(f\"Count of models with 'No data found' for all 32 years: {len(models_with_no_mpg_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0d2428-3da1-4b25-aa1b-6fd15a50648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/merged_all_years.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b879b2f0-1852-4bc4-b2ab-3983a8bcf19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_KEY = \"P04GoFxpHEUgM6Ov5kq5HQ==jqq9qjnuBwvQ3ZzA\"  # Replace with your actual API key\n",
    "url = \"https://api.api-ninjas.com/v1/cars?make=niss\"  # Example endpoint\n",
    "\n",
    "headers = {\"X-Api-Key\": API_KEY}\n",
    "all_models = []\n",
    "\n",
    "# Loop through multiple pages if pagination is needed\n",
    "page = 1\n",
    "while True:\n",
    "    response = requests.get(url + f\"&page={page}\", headers=headers)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(\"Error:\", response.status_code, response.text)\n",
    "        break\n",
    "\n",
    "    data = response.json()\n",
    "    if not data:  # If no more data, stop\n",
    "        break\n",
    "\n",
    "    all_models.extend([car[\"model\"] for car in data])\n",
    "    page += 1  # Move to the next page\n",
    "\n",
    "print(all_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b098d052-deec-4537-a1a2-803c85ee15cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered VINs and years saved to 'models_with_vins.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "models_df = pd.read_csv(\"C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/models_with_no_mpg_data.csv\")  # Contains unique model names\n",
    "merged_df = pd.read_csv(\"C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/merged_all_years.csv\")  # Contains 'Model', 'VIN', and 'Year' columns\n",
    "\n",
    "# Extract model names\n",
    "model_names = models_df['model'].tolist()  # Convert model names to a list\n",
    "\n",
    "# Filter the merged dataset based on model names\n",
    "filtered_df = merged_df[merged_df['model'].isin(model_names)][['model', 'vin', 'my']]\n",
    "\n",
    "# Save the result to a CSV file\n",
    "filtered_df.to_csv(\"C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/models_with_vins.csv\", index=False)\n",
    "\n",
    "print(\"Filtered VINs and years saved to 'models_with_vins.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17b0c9e3-0032-4e5d-a201-ce52db62031b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Batch 1... (VINs 1 to 100)\n",
      "✔️ Batch 1 completed! Processed 100 VINs so far. Time elapsed: 5.02 seconds.\n",
      "Processing Batch 2... (VINs 101 to 200)\n",
      "✔️ Batch 2 completed! Processed 200 VINs so far. Time elapsed: 9.47 seconds.\n",
      "Processing Batch 3... (VINs 201 to 300)\n",
      "✔️ Batch 3 completed! Processed 300 VINs so far. Time elapsed: 13.44 seconds.\n",
      "Processing Batch 4... (VINs 301 to 400)\n",
      "✔️ Batch 4 completed! Processed 400 VINs so far. Time elapsed: 19.32 seconds.\n",
      "Processing Batch 5... (VINs 401 to 458)\n",
      "✔️ Batch 5 completed! Processed 458 VINs so far. Time elapsed: 22.06 seconds.\n",
      "\n",
      "✅ Processing complete! Results saved to C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/models_with_no_mpg_data_vin_and_model.csv\n",
      "Total time taken: 22.06 seconds.\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "# Database connection\n",
    "conn = pyodbc.connect('DRIVER={SQL Server};SERVER=manpreets_asus;DATABASE=vPICList_Lite1;Trusted_Connection=yes;')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Load the CSV file containing VINs\n",
    "input_csv = \"C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/models_with_no_mpg_data_vin.csv\"  # Replace with your CSV file path\n",
    "output_csv = \"C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/models_with_no_mpg_data_vin_and_model.csv\"  # Output file\n",
    "vin_df = pd.read_csv(input_csv)\n",
    "\n",
    "# Ensure the CSV has a column named 'VIN'\n",
    "if 'vin' not in vin_df.columns:\n",
    "    raise ValueError(\"CSV file must contain a column named 'VIN'\")\n",
    "\n",
    "# Prepare a list to store results\n",
    "results = []\n",
    "\n",
    "# Process VINs in batches (to avoid overloading the database)\n",
    "batch_size = 100  # Adjust batch size based on DB performance\n",
    "total_vins = len(vin_df)\n",
    "start_time = time.time()\n",
    "# Check if output file exists to determine if header is needed\n",
    "file_exists = os.path.isfile(output_csv)\n",
    "\n",
    "for i in range(0, total_vins, batch_size):\n",
    "    batch_vins = vin_df['vin'][i:i+batch_size]\n",
    "    batch_num = (i // batch_size) + 1\n",
    "    print(f\"Processing Batch {batch_num}... (VINs {i+1} to {i+len(batch_vins)})\")\n",
    "\n",
    "    results = []  # Store results for the current batch\n",
    "\n",
    "    for vin in batch_vins:\n",
    "        cursor.execute(\"EXEC [dbo].[spVinDecode] @v = ?\", vin)\n",
    "        query_results = cursor.fetchall()\n",
    "\n",
    "        # Extract column names\n",
    "        columns = [column[0] for column in cursor.description]\n",
    "        variable_idx = columns.index(\"Variable\")\n",
    "        value_idx = columns.index(\"Value\")\n",
    "\n",
    "        # Find the Model value\n",
    "        model_name = None\n",
    "        for row in query_results:\n",
    "            if row[variable_idx] == \"Model\":\n",
    "                model_name = row[value_idx]\n",
    "                break  # Stop after finding the model\n",
    "\n",
    "        # Append result (VIN, Model)\n",
    "        results.append([vin, model_name if model_name else \"Not Found\"])\n",
    "\n",
    "    # Convert batch results to DataFrame\n",
    "    batch_df = pd.DataFrame(results, columns=['VIN', 'Model'])\n",
    "\n",
    "    # Write batch to CSV, append mode ('a'), add header only for the first batch\n",
    "    batch_df.to_csv(output_csv, mode='a', header=not file_exists, index=False)\n",
    "\n",
    "    # Update file existence flag after first batch\n",
    "    file_exists = True  \n",
    "\n",
    "    # Print progress update\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"✔️ Batch {batch_num} completed! Processed {i+len(batch_vins)} VINs so far. Time elapsed: {elapsed_time:.2f} seconds.\")\n",
    "\n",
    "print(f\"\\n✅ Processing complete! Results saved to {output_csv}\")\n",
    "print(f\"Total time taken: {time.time() - start_time:.2f} seconds.\")\n",
    "\n",
    "# Close database connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ce80d33-9678-4bbb-acba-0adf09ee721a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved as 'merged_output.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the first CSV file (e.g., model list with VIN)\n",
    "file1 = pd.read_csv(\"C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/models_with_no_mpg_data_vin.csv\")  # Ensure this file has a 'VIN' column\n",
    "\n",
    "# Load the second CSV file (e.g., merged dataset with VIN)\n",
    "file2 = pd.read_csv(\"C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/models_with_no_mpg_data_vin_and_model.csv\")  # Ensure this file has a 'VIN' column\n",
    "\n",
    "# Merge both files on the 'VIN' column\n",
    "merged_df = file1.merge(file2, on=\"vin\", how=\"inner\")  # Use 'left' if you want all records from file1\n",
    "\n",
    "# Save the merged file as a CSV\n",
    "merged_df.to_csv(\"C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/models_renamed.csv\", index=False)\n",
    "\n",
    "print(\"CSV file saved as 'merged_output.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4b708d0-6425-4e32-8843-fb6fbad30faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved as 'updated_merged_all_years.csv' with 'model_api' correctly mapped. Missing values replaced with model names.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the smaller file (with 'model' and 'model_api' columns)\n",
    "small_df = pd.read_csv(\"C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/models_renamed.csv\")\n",
    "\n",
    "# Load the bigger file (which contains the 'model' column)\n",
    "big_df = pd.read_csv(\"C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/merged_all_years.csv\")\n",
    "\n",
    "# Ensure the 'model' column is clean (removing leading/trailing spaces)\n",
    "small_df[\"model\"] = small_df[\"model\"].astype(str).str.strip()\n",
    "big_df[\"model\"] = big_df[\"model\"].astype(str).str.strip()\n",
    "\n",
    "# Merge to bring 'model_api' into big_df based on the 'model' column\n",
    "big_df = big_df.merge(small_df[[\"model\", \"model_api\"]], on=\"model\", how=\"left\")\n",
    "\n",
    "# Fill missing model_api values with the model itself\n",
    "big_df[\"model_api\"] = big_df[\"model_api\"].fillna(big_df[\"model\"])\n",
    "\n",
    "# Save the updated DataFrame\n",
    "big_df.to_csv(\"C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/updated_merged_all_years.csv\", index=False)\n",
    "\n",
    "print(\"CSV file saved as 'updated_merged_all_years.csv' with 'model_api' correctly mapped. Missing values replaced with model names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7df960b-d717-4b56-ba2f-5af5a18f555d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered file saved as C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/models_filtered.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the file\n",
    "file_path = \"C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/models_renamed.csv\"  # Replace with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure column names are correctly interpreted\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Filter rows where stripped values of \"model\" and \"model_api\" are different\n",
    "filtered_df = df[df[\"model\"].astype(str).str.strip() != df[\"model_api\"].astype(str).str.strip()]\n",
    "\n",
    "# Save the filtered data to a new file\n",
    "filtered_file_path = \"C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/models_filtered.csv\"  # Output file name\n",
    "filtered_df.to_csv(filtered_file_path, index=False)\n",
    "\n",
    "print(f\"Filtered file saved as {filtered_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d84221aa-4f10-4cd4-bd60-b35202ff5030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned file saved as C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/models_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the filtered file\n",
    "file_path = \"C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/models_filtered.csv\"  # Replace with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure column names are correctly interpreted\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Remove rows where \"model_api\" is \"Not Found\" (after stripping whitespace)\n",
    "df = df[df[\"model_api\"].astype(str).str.strip() != \"Not Found\"]\n",
    "\n",
    "# Save the cleaned data to a new file\n",
    "cleaned_file_path = \"C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/models_cleaned.csv\"  # Output file name\n",
    "df.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(f\"Cleaned file saved as {cleaned_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ff7f89d-ad0c-4a11-b441-ba03bc9a228a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV with models and years has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "# Load the model names and years from the CSVs\n",
    "# Load the cleaned file\n",
    "file_path = \"C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/models_cleaned.csv\"  # Replace with the actual path if needed\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Read the \"model_api\" column and convert it into a list\n",
    "model_names = df[\"model_api\"].astype(str).str.strip().tolist()\n",
    "\n",
    "with open('C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/unique_my.csv', 'r') as f:\n",
    "    model_years = f.read().splitlines()\n",
    "\n",
    "# Prepare a list to store the combined model-year pairs\n",
    "combined_data = []\n",
    "\n",
    "# Loop through each model name and combine with each year\n",
    "for model in model_names:\n",
    "    for year in model_years:\n",
    "        combined_data.append([model, year])\n",
    "\n",
    "# Write the combined data into a new CSV file\n",
    "with open('C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/combined_model_api_year.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['model', 'my'])  # Write the header\n",
    "    writer.writerows(combined_data)  # Write the data rows\n",
    "\n",
    "print(\"CSV with models and years has been created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "246464b8-62c1-4636-a94d-dcfc530c39f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import urllib.parse\n",
    "# Load car model dataset from CSV file\n",
    "input_csv = \"C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/combined_model_api_year.csv\"  # Replace with your CSV file path\n",
    "output_csv = \"C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/mpg_new_models_2.csv\"  # Output file where you will save the results\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(input_csv)\n",
    "df_first = df.iloc[9000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12dd24c1-439a-4baa-ae36-ee23d06e8c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = df_first['model'].tolist()  # Assuming the column with model names is 'Model'\n",
    "model_years = df_first['my'].tolist()\n",
    "# List to store the results\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f43422de-c024-415f-a1a7-70bf77c4c83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/mpg_new_models_2.csv\n"
     ]
    }
   ],
   "source": [
    "# Loop through each model and make the API request\n",
    "for model, year in zip(models, model_years):\n",
    "    #model_encoded = urllib.parse.quote(str(model))\n",
    "    api_url = f'https://api.api-ninjas.com/v1/cars?model={model}&year={year}'\n",
    "    headers = {'X-Api-Key': 'dvuBASP3Gm+z+ouYWFlRHw==I3uokOnmXtiENczp'}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(api_url, headers=headers)\n",
    "\n",
    "        if response.status_code == requests.codes.ok:\n",
    "            car_data = response.json()\n",
    "            combination_mpg = car_data[0].get('combination_mpg', 'Combination MPG not available') if car_data else 'No data found'\n",
    "        else:\n",
    "            combination_mpg = f\"Error {response.status_code}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        combination_mpg = f\"Request failed: {str(e)}\"\n",
    "\n",
    "    results.append({'Model': model, 'Model Year': year, 'Combination MPG': combination_mpg})\n",
    "    #time.sleep(1)  # Prevent API rate limits\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Results saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "947489b6-9d04-4c6a-9889-8ae6509eb9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned file saved as C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/ninja_api_results_full_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the filtered file\n",
    "file_path = \"C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/ninja_api_results_full.csv\"  # Replace with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure column names are correctly interpreted\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Remove rows where \"model_api\" is \"Not Found\" (after stripping whitespace)\n",
    "df = df[df[\"CombinationMPG\"].astype(str).str.strip() != \"No data found\"]\n",
    "\n",
    "# Save the cleaned data to a new file\n",
    "cleaned_file_path = \"C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/ninja_api_results_full_cleaned.csv\"  # Output file name\n",
    "df.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(f\"Cleaned file saved as {cleaned_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4d73b18-a8a3-47ab-9bbe-decdf40f65d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 vin      zipcode  odometer test_date  make          model  \\\n",
      "0  WBAEV33452KL68783  606551055.0    125000  6/1/2020  BMW        3 Series   \n",
      "1  1GBFG15R6Y1100200  606321626.0    206000  6/1/2020  CHEV  Express Cargo   \n",
      "2  1GCDT136548185796  605011310.0    109000  6/1/2020  CHEV       Colorado   \n",
      "3  2GKALMEK0C6364495  604534400.0     80000  6/1/2020  GMC         Terrain   \n",
      "4  1HGCG1652YA094701  604591106.0    167000  6/1/2020  HOND         Accord   \n",
      "\n",
      "     my purchase_date      model_api     Model  ModelYear  CombinationMPG  \n",
      "0  2002      5/1/2021           325i       NaN        NaN             NaN  \n",
      "1  2000     5/21/2017  Express Cargo       NaN        NaN             NaN  \n",
      "2  2004     6/18/2013       Colorado  Colorado     2004.0            18.0  \n",
      "3  2012     4/26/2018        Terrain   Terrain     2012.0            20.0  \n",
      "4  2000     7/19/2014         Accord    Accord     2000.0            23.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your datasets\n",
    "large_df = pd.read_csv('C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/merged_dataset2.csv')  # replace with your larger dataset path\n",
    "small_df = pd.read_csv('C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/mpg_new_models_2.csv')  # replace with your smaller dataset path\n",
    "\n",
    "# Merge the datasets to find matching values\n",
    "merged_df = pd.merge(large_df, small_df, how='left', left_on=['model_api', 'my'], right_on=['Model', 'ModelYear'])\n",
    "\n",
    "# Update the CombinationMPG column only where there is a match\n",
    "large_df.loc[merged_df['CombinationMPG'].notna(), 'CombinationMPG'] = merged_df['CombinationMPG']\n",
    "\n",
    "# The 'CombinationMPG' from the small file will be added to the merged dataset\n",
    "# Save the merged dataset to a new file if needed\n",
    "large_df.to_csv('C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/merged_dataset3.csv', index=False)\n",
    "\n",
    "# If you'd like to see the first few rows of the merged dataset\n",
    "print(large_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21d60287-d828-46b4-b8f5-e6aab9cb90a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated file saved as: C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/merged_dataset3_updated.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path\n",
    "input_file = r'C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/merged_dataset3.csv'\n",
    "output_file = r'C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/merged_dataset3_updated.csv'\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Drop the columns 'Model' and 'ModelYear'\n",
    "df.drop(columns=['Model', 'ModelYear'], inplace=True)\n",
    "\n",
    "# Save the updated dataset with a new name\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "# Print confirmation message\n",
    "print(f\"Updated file saved as: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "beb0a8a4-c73b-4136-ade4-7c68ea616b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the dataset: 8345645\n",
      "Number of null values in 'CombinationMPG' column: 1843\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = \"C:/Users/kaur6/Downloads/Urban Analytics/Odometer Data-Full/ninja_api_results/merged_dataset3_updated.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "# Count the number of missing (null) values in the CombinationMPG column\n",
    "null_count = df['CombinationMPG'].isna().sum()\n",
    "# Print results\n",
    "print(f\"Number of rows in the dataset: {df.shape[0]}\")\n",
    "print(f\"Number of null values in 'CombinationMPG' column: {null_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268cb165-fd79-494e-b9ad-820bfa69717f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
